## Overview

This directory contains notebooks showcasing a demonstration of 6 different parts of our process. All notebooks assume that the virtual environment in [`../environment.yml`](../environment.yml) is fully set up.

1. [`Parallelized_Image_Loading.ipynb`](./Parallelized_Image_Loading.ipynb): A walkthrough of how to intake images from Azure Blob and perform model predictions in parallel on CPU.
   - **Output:** [`./data/inventory_df_with_probs.parquet.gzip`](./data/inventory_df_with_probs.parquet.gzip), a 1.1M row dataframe with image file paths, image predicted label, and class probabilities for each image for all 10 classes.
   - **Main Takeaways:** Obtaining model predictions for 1M images took approximately 8 hours and was not a stable connection. This code should eventually be optimized to run on a VM as a scheduled batch job as new data comes in.
     - Currently, we use a preset CSV generated by Ali Chase in her workflow that contains the local imagepath (easily modified to yield the blob path), and the final class prediction for the model. If her current workflow can be toggled to also store the classes, this doesn't need to be done.
     - This was an initial step to check whether smarter ways of computing were necessary and the outcome is that CSV files are bulky, especially when there are multiple iterations of the model afoot.
2. [`Parallelized_Feature_Vectors.ipynb`](./Parallelized_Feature_Vectors.ipynb): A walkthrough of how to take images from Azure Blob and visualize them in high dimensional space using the pre-softmax output of the CNN model.
   - **Main Takeaways**: The `Other` and `Unidentifiable` classes overlap heavily with the other classes. A two-step model approach to first filter these out and then classify between the rest should be explored. Some classes like `Diatom` wind around heavily in high-dimensional space showcasing that it requires a lot more imagery to potentially understand the full scope of this class.
     - Computing vectors is computationally challenging and should only be done once and never on the fly. Attempts to store a vector per image on Blob were rejected as they incur infeasible I/O costs. Instead, a subsampled set of 100K images is stored as `./data/total_downsampled.pickle.gz`, which is a dictionary of I_IDs, and an NxD1 and NxD2 matrices where D1 represents the dimensionality of the data just after the CNN layer while D2 is the representation after popping the last layer. These two matrices are keyed by 'post_cnn' & 'pop_last', respectively. `pop_last` is much greater than `post_cnn` in both clustering & size. As such, we elect to go with `pop_last`.
       - In the future, batches of I_IDs can be stored and the relevant chunks can be retrieved when data needs to be looked at. 
3. [`Uncertainty_Scores.ipynb`](./Uncertainty_Scores.ipynb): An exploration of multiple avenues of calculating the model's uncertainty estimates for each new image. Specifically, we write code to explore **Uncertainty-based Querying**, in which the model selects instances for labeling that exhibit the highest uncertainty of the class probabilities associated with each instance. These methods have the benefit of both priming the next set of images to retrain the model and allowing for an easy thresholding below which, we wouldn't need to validate the model's prediction at all.
   - We look at the following methods:
      - **Least Margin**: Uncertainty is defined as the margin between the predicted probabilities of the top two candidate classes. Instances with lower margins are considered to be more uncertain.
      - **Least Confidence**: Uncertainty is measured by the maximal class probability value, with lower maximal class probabilities denoting more uncertainty.
      - **Entropy**: Uncertainty is measured as entropy (H(x)), with higher entropy denoting more uncertainty. 
   - **Output:** [`./data/inventory_df_with_scores.parquet.gzip`](./data/inventory_df_with_scores.parquet.gzip), a 1.1M row dataframe with image file paths, image predicted label, and uncertainty measure for Entropy, Least Confidence, and Least Margin.
   - **Main Takeaways:** Entropy appears to be a good first bet for thresholding and for active learning loops. It has a steady decrease in frequency at higher uncertainty scores across both seen and unseen data. Additionally, on seen data (train data), there is a natural inflection point at 0.6 above which the accuracy drops steeply.
     - For 85% Accuracy: 94.77% of the data can be auto-labeled.
     - For 90% Accuracy: 78.58% of the data can be auto-labeled.
     - For 95% Accuracy: 50.65% of the data can be auto-labeled.
     - For 100% Accuracy: 0.32% of the data can be auto-labeled.
4. [`SQL_Queries.ipynb`](./SQL_Queries.ipynb): A demonstration of how to use our Python-wrapped SQL utility functions located in `../PIVOT/utils/sql_utils/`.
   - **Main Takeaways:** We use [PYMSSQL](https://pymssql.readthedocs.io/en/stable/index.html) as our interface of choice to link Python with Azure SQL for easy access with minimal dependencies.
     - **Stored Procedures** increase computational efficiency and we wrote wrapper functions to call them with default arguments.
     - **WARNING:** DO NOT DELETE RECORDS IN `LABELS` TABLE WITHOUT USING `sql_utils.delete_labels_cleanup()`.
   - **Dependencies:** Azure SQL & authentication in [`../PIVOT/config/config.yaml`](../PIVOT/config/config.yaml).
5. [`Initial_Data_Ingestion.ipynb`](./Initial_Data_Ingestion.ipynb): A walkthrough of how to load data to Azure SQL for the first time, using local files stored in [`./data/inventory_df_with_probs.parquet.gzip`](./data/inventory_df_with_probs.parquet.gzip) and [`../PIVOT/data/model-summary-cnn-v1-b3.csv`](../PIVOT/data/model-summary-cnn-v1-b3.csv).
6. [`Testing_Model_Serving.ipynb`](./Testing_Model_Serving.ipynb): In this notebook, we access the deployed model via its REST endpoint and make predictions using a small subset of test data.
   - **Dependencies:** Azure ML & authentication in [`../PIVOT/config/config.yaml`](../PIVOT/config/config.yaml).
7. [`Experiment_RepeatedSampling.ipynb`](./Experiment_RepeatedSampling.ipynb): A back of the napkin, unvalidated experiment attempting to eyeball what decay rate is required to minimize the chances of relabeling the same image.
   - **Main Takeaway**: We use an exponential decay with lambda= 0.069 as this scales the most uncertain image to the middle of the original rank if we label it 10x (what we set as our consensus for labeling.)

In addition to the notebooks, in `./models/`, we have the TensorFlow files to load in the latest model developed at UTOPIA by Ali Chase sourced from their [repository](https://github.com/ifcb-utopia/ml-workflow/blob/main/model_ckpt/). The `./data/` folder contains temporary data for experimenting & demonstration purposes only.
